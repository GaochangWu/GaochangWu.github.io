<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>SAA-Net's Project Page</title>
<!-- Bootstrap -->
<link href="./css/bootstrap-4.0.0.css" rel="stylesheet">
</head>
<body>
<div id="page_container">
<header>
  <div class="jumbotron" >
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h5 class="text-left"><a href="https://gaochangwu.github.io/">Back to my homepage</a></h5> <h5 class="text-center">arXiv 2020</h5>
          <h2 class="text-center">Spatial-Angular Attention Network for Light Field Reconstruction</h1>
          <p class="text-center">&nbsp;</p>
          <h6 class="text-center"><a href="https://gaochangwu.github.io/">Gaochang Wu</a><sup>1</sup>, Yingqian Wang<sup>2</sup>, <a href="http://www.liuyebin.com/">Yebin Liu</a><sup>3</sup>, <a href="http://luvision.net/">Lu Fang</a><sup>4</sup>, Tianyou Chai</a><sup>1</sup></h6>
          <p class="text-center">1. Northeastern University, 2. Nation University of Defense Technology, 3. Tsinghua University, 4. Tsinghua-Berkeley Shenzhen Institute</p>
        </div>
      </div>
    </div>
  </div>
</header>
<section>
  <div class="container">
    <p>&nbsp;</p>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Abstract</h2>
      </div>
    </div>
  </div>
  <div class="container ">
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center  offset-xl-0 col-xl-12">
        <p class="text-left"><em>Learning-based light field reconstruction methods demand in constructing a large receptive field by deepening the network to capture correspondences between input views. In this paper, we propose a spatial-angular attention network to perceive correspondences in the light field non-locally, and reconstruct high angular resolution light field in an end-to-end manner. Motivated by the non-local attention mechanism [1], [2], a spatialangular attention module specifically for the high-dimensional light field data is introduced to compute the responses from all the positions in the epipolar plane for each pixel in the light field, and generate an attention map that captures correspondences along the angular dimension. We then propose a multi-scale reconstruction structure to efficiently implement the non-local attention in the low spatial scale, while also preserving the high frequency components in the high spatial scales. Extensive experiments demonstrate the superior performance of the proposed spatialangular attention network for reconstructing sparsely-sampled light fields with non-Lambertian effects.
 </em></p>
        <p class="text-left">&nbsp;</p>
        <p class="text-left">&nbsp;</p>
        <img src="assets/teaser.png" width="500" alt=""/>
        <p>Fig 1.&nbsp;We propose a spatial-angular attention module embedded in a multiscale reconstruction structure for learning-based light field reconstruction.</p>
        <p>&nbsp;</p>
      </div>
    </div>
    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Results </h2>
        <p>&nbsp;</p>
      </div>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-0 col-xl-10"> <img src="assets/results_large1.png" width="1055" alt=""/>
        <p>&nbsp;</p>
        <p class="text-center">Fig 2. Demonstration of attention map on scenes with (a) large disparity and (b) non-Lambertian effect.</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>
	<div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-0 col-xl-10"> <img src="assets/results_large2.png" width="1055" alt=""/>
        <p>&nbsp;</p>
        <p class="text-center">Fig 3. Comparison of the results on the light fields from the CIVIT Dataset (16x upsampling).</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-0 col-xl-10"> <img src="assets/results_large3.png" width="1055" alt=""/>
        <p>&nbsp;</p>
        <p class="text-center">Fig 4. Comparison of the results on the light fields from the MPI Light Field Archive (16x upsampling).</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>
    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Technical Paper</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center"> <a href="assets/SAA-Net.pdf"><img src="assets/paper.png" width="1000" alt=""/></a>
      <p>&nbsp;</p>
    </div>
    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Citation</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-left">
      <p><span style="color:#000000;font-family:'Courier New';font-size:15px;"> Gaochang Wu, Yingqian Wang, Yebin Liu, Lu Fang, Tianyou Chai. "Spatial-Angular Attention Network for Light Field Reconstruction". IEEE Transactions on Image Processing, 2021, 1-1</span></p>
      <p>&nbsp;</p>
      <p><span style="color:#000000;font-family:'Courier New';font-size:15px;">@misc{wu2019lapepi, <br>
			title={Spatial-Angular Attention Network for Light Field Reconstruction},<br>
			author={Gaochang Wu and Yebin Liu and Lu Fang and Tianyou Chai},<br>
			year={2020},<br>
			journal={IEEE Transactions on Image Processing},<br>
			pages={1-1},<br>
		}</span></p>
      <p>&nbsp;</p>
      <p>&nbsp;</p>
    </div>
    <div class="row"> </div>
  </div>
  <div class="jumbotron"> </div>
</section>	
</div>

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) --> 
<script src="./js/jquery-3.2.1.min.js"></script> 
<!-- Include all compiled plugins (below), or include individual files as needed --> 
<script src="./js/popper.min.js"></script> 
<script src="./js/bootstrap-4.0.0.js"></script>
</body>
</html>
