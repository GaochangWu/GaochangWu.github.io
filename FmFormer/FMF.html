<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>FmFormer's Project Page</title>
<!-- Bootstrap -->
<link href="./css/bootstrap-4.0.0.css" rel="stylesheet">
</head>
<body>
<div id="page_container">
<header>
  <div class="jumbotron" >
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h5 class="text-left"><a href="https://gaochangwu.github.io/">Back to my homepage</a></h5> <h5 class="text-center">Accepted by IEEE TCSVT 2024</h5>
          <h2 class="text-center">Cross-Modal Learning for Anomaly Detection in Complex Industrial Process: Methodology and Benchmark</h1>
          <p class="text-center">&nbsp;</p>
          <h6 class="text-center"><a href="https://gaochangwu.github.io/">Gaochang Wu</a><sup>1</sup>, Yapeng Zhang</a><sup>1</sup>, Lan Deng</a><sup>1</sup>, Jingxin Zhang</a><sup>2</sup>, Tianyou Chai</a><sup>1</sup></h6>
          <p class="text-center">1. Northeastern University, 2. Swinburne University of Technology</p>
        </div>
      </div>
    </div>
  </div>
</header>
<section>
  <div class="container">
    <p>&nbsp;</p>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Abstract</h2>
      </div>
    </div>
  </div>
  <div class="container ">
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center  offset-xl-0 col-xl-12">
        <p class="text-left"><em>Anomaly detection in complex industrial processes plays a pivotal role in ensuring efficient, stable, and secure operation. Existing anomaly detection methods primarily focus on analyzing dominant anomalies using the process variables (such as arc current) or constructing neural networks based on abnormal visual features, while overlooking the intrinsic correlation of cross-modal information. This paper proposes a cross-modal Transformer (dubbed FmFormer), designed to facilitate anomaly detection by exploring the correlation between visual features (video) and process variables (current) in the context of the fused magnesium smelting process. Our approach introduces a novel tokenization paradigm to effectively bridge the substantial dimensionality gap between the 3D video modality and the 1D current modality in a multiscale manner, enabling a hierarchical reconstruction of pixel-level anomaly detection. Subsequently, the FmFormer leverages self-attention to learn internal features within each modality and bidirectional cross-attention to capture correlations across modalities. By decoding the bidirectional correlation features, we obtain the final detection result and even locate the specific anomaly region. To validate the effectiveness of the proposed method, we also present a pioneering cross-modal benchmark of the fused magnesium smelting process, featuring synchronously acquired video and current data for over 2.2 million samples. Leveraging cross-modal learning, the proposed FmFormer achieves state-of-the-art performance in detecting anomalies, particularly under extreme interferences such as current fluctuations and visual occlusion caused by heavy water mist. The presented methodology and benchmark may be applicable to other industrial applications with some amendments. The benchmark will be released at \url{https://github.com/GaochangWu/FMF-Benchmark}.
</em></p>
    <h5 class="text-center"><a href="https://www.bilibili.com/video/BV1sV411H7hF/">[Interpolation Video]</a> <a href="https://www.bilibili.com/video/BV1aK4y1K7Wg/">[Extrapolation Video]</a> <a href="https://github.com/GaochangWu/DA2N">[Code]</a></h5>
        <img src="assets/teaser.png" width="500" alt="">
        <p>Fig 1.&nbsp;Schematic diagram of the proposed Deep Anti-Aliasing Network (DA<sup>2</sup>N) with embedding shearing, downscaling and prefiltering. In the result, we use input views indicated by the red lines for the EPI reconstruction, including interpolation and extrapolation.</p>
        <p>&nbsp;</p>
      </div>
    </div>
    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Network </h2>
        <p>&nbsp;</p>
      </div>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center"> <img src="assets/CNN.png" width="1000" alt=""/>
        <p>&nbsp;</p>
        <p>Fig 2.&nbsp;Architecture of the proposed deep anti-aliasing network (DA<sup>2</sup>N) based on shearing, downscaling and prefiltering.</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>
	<hr>
	<div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Results </h2>
        <p>&nbsp;</p>
      </div>
    </div>
	<div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center"> <img src="assets/results_large2.png" width="800" alt=""/>
        <p>&nbsp;</p>
        <p>Fig 3. Comparison of the results (x16 upsampling) on the LFs from the ICME DSLF dataset.</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 text-center"> <img src="assets/results_large3.png" width="800" alt=""/>
        <p>&nbsp;</p>
        <p class="text-center">Fig 4. Comparison of the results (16x upsampling) on the light fields from the MPI Light Field Archive.</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
    </div>
    <hr>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Technical Paper</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center"> <a href="https://arxiv.org/abs/2104.06797"><img src="assets/paper.png" width="500" alt=""/></a>
      <p>&nbsp;</p>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Supplemental Material</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center"> <a href="assets/supplementary.pdf"><img src="assets/supp.png" width="300" alt=""/></a>
      <p>&nbsp;</p>
    </div>
    <div class="row">
      <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
        <h2>Citation</h2>
      </div>
    </div>
    <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-left">
      <p><span style="color:#000000;font-family:'Courier New';font-size:15px;"> Gaochang Wu, Yebin Liu, Lu Fang, Tianyou Chai. "Revisiting Light Field Rendering with Deep Anti-Aliasing Neural Network," IEEE Transactions on Pattern Analysis and Machine Intelligence, to be published</span></p>
      <p>&nbsp;</p>
      <p><span style="color:#000000;font-family:'Courier New';font-size:15px;">@article{wu2021revisiting, <br>
			title={Revisiting Light Field Rendering with Deep Anti-Aliasing Neural Network},<br>
			author={Gaochang Wu and Yebin Liu and Lu Fang and Tianyou Chai},<br>
			year={to be published},<br>
			journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}<br>
		}</span></p>
      <p>&nbsp;</p>
      <p>&nbsp;</p>
    </div>
    <div class="row"> </div>
  </div>
  <div class="jumbotron"> </div>
</section>	
</div>

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) --> 
<script src="./js/jquery-3.2.1.min.js"></script> 
<!-- Include all compiled plugins (below), or include individual files as needed --> 
<script src="./js/popper.min.js"></script> 
<script src="./js/bootstrap-4.0.0.js"></script>
</body>
</html>
